- 选择
- 填空
- 计算：
  - 第一章：CPI、CPU 时间、MIPS、加速比等
  - 第三章：流水线
  - 第四章：向量链接、编队
  - 第九章：互联网络
- 综合：
  - 第一章简答题
  - 第九章互联网络、第十章状态转移图
  - 第三章流水线、第五章前瞻执行
  - 第五章动态调度


# 第一章、基础知识
## 相关概念
层次结构：计算机是由硬件、软件、固件（固化的微程序）组成的复杂系统，按机器语言功能划分为多级层次结构。

- **计算机系统结构**
 > **传统机器程序员**所看到的计算机属性，即**概念性结构**、**功能特性**。
 > 实质：**确定计算机系统中软硬件的界面**，界面之上是软件实现的功能，界面之下是硬件和固件实现的功能。
 > **广义系统结构定义**：包括指令系统结构、组成、硬件。

- Flynn 分类法：按照指令流和数据流的多倍性分类。
 > SISD（传统顺序处理计算机）
 > SIMD（阵列处理机）
 > MISD（流水处理机，有争议）
 > MIMD（多处理机）系统
 
![](Attachments/Pasted%20image%2020250621150215.png)

## 基本原理和性能公式
- 大概率事件优先
 > 优先加速使用频率高的部件
 > **最重要和最广泛采用的计算机设计准则**

- Amdahl 定律
 > 系统性能加速比与该部件在系统中的总执行时间有关
 > $$加速比S_n = \frac{改进后性能}{改进前性能} = \frac{改进前用时}{改进后用时} = \frac{T_0}{T_n} = \frac{1}{(1- F_e)+\frac{F_e}{S_e}}$$
 > Fe为可改进比例（该功能占系统总运行/操作的比例），Se为部件加速比
 > 重要推论：如果只针对整个任务的一部分进行改进和优化，那么所获得的加速比不超过：
 > > 1/（1-Fe） 

- CPU 性能计算
 > CPU 时间：执行一个程序所需 CPU 时间
 > ![](Attachments/Pasted%20image%2020250621153848.png)

- **加速比公式应用**
看习题 

## 性能评价标准
- **性能指标**（CPU 时间、**CPI**、MIPS、MFLOPS）

“X 的性能是 Y 的 n 倍”：$n=\frac{执行时间Y}{执行时间X}=\frac{性能x}{性能y}$

总时间 = CPU 时间 + I/O 时间 + 运行其他程序的时间

CPU 时间 = 用户 CPU 时间 + 系统 CPU 时间

![](Attachments/Pasted%20image%2020250621160216.png)

---

# 第三章、流水线技术
## 基本概念及分类
- 流水线技术
 > 主要思想：把**一个复杂任务分解为若干个子任务**。每个子任务由专门功能部件完成，并使多个子任务**并行执行**。
 > **核心**：部件功能专用化
 > 流水线中每个**子过程**及其功能部件，称为**一个流水段**
 > 流水线的段数称为**流水线深度**（长度）
 > 指令通过流水线时间最长的**段**称为**流水线瓶颈**
 > 每段流水线后面有一个缓冲寄存器，称为**流水寄存器**。有**缓冲、隔离、同步**作用。


## 流水线表示
**时空图、连接图**

## 性能计算和分析
吞吐率 TP、加速比 S、效率 E
- TP
 > **单位时间内**流水线完成的任务数量或输出结果的数量
 > $TP=\frac{n}{T_k}$
 > ![](Attachments/Pasted%20image%2020250621163612.png)

- S
 > 完成同样任务，**不使用流水线所用时间**与**使用流水线所用时间**之比。
 > $S=\frac{T_s}{T_k}$
 > ![](Attachments/Pasted%20image%2020250621163830.png)

- E
 > **流水线中的设备实际使用时间与整个运行时间的比值**，又称流水线设备利用率。
 > ![](Attachments/Pasted%20image%2020250621164434.png)

解决流水线瓶颈的方法：
- 重复设置瓶颈段：让多个瓶颈流水段并行工作。
- 瓶颈段再细分：细分为多个子流水段（每个子流水段用时和非瓶颈段相同），形成超流水线。

- 大于等于 8 段的流水线称为超流水线。
## 流水线相关与冲突
IF 取指令
ID 指令译码
EX 执行 
MEM 一些存储指令（ALU 指令此周期不执行操作）
WB 结果写入通用寄存器组

默认写操作在前半拍，读操作在后半拍

- 数据相关、名相关、控制相关
 > **数据相关**：
 > > 1. 指令 a 使用指令 b 产生的结果
 > > 2. 指令 a 与指令 b 数据相关，而指令 b 与指令 c 数据相关
 > 
 > **名相关：** 两条指令使用了相同的名（访问的寄存器/存储器的名称），但并没有数据流动关系
 > > **反相关**：指令 b **写**的名与指令 a **读**的名相同。反相关指令之间的执行顺序必须严格遵守，保证 b 读的值是正确的。
 > > **输出相关**：指令 b 与指令 a **写**的名相同。输出相关指令的执行顺序也必须严格遵守，保证最后的结果是指令 b 写进去的。
 > 
 > **控制相关**：分支指令和其它会**改变 PC 值**的指令引起的相关

- **结构冲突、数据冲突、控制冲突**
 > **结构冲突**：某种指令组合因为硬件资源冲突而不能正常执行。功能部件不是完全流水或硬件资源份数不够时发生。解决方法：插入暂停周期，或增加 Cache 等硬件资源。
 > **数据冲突**：
 > > 写后读冲突（RAW、WR）：对应真（数据）相关
 > > 写后写冲突（WAW、WW）：对应输出相关
 > > 读后写冲突（WAR、RW）：对应反相关
 > > **解决办法**：
 > > > 使用**定向技术**（旁路技术）减少数据冲突引起的停顿
 > > > 需要**停顿**的数据冲突
 > > > 依靠**编译器**解决数据冲突（指令调度、流水线调度）
 > 
 > **控制冲突**：分支指令和其它会改变 PC 值的指令引起的冲突。

---

# 第四章、向量处理机
向量处理方法：横向处理、纵向处理、纵横处理
- **纵向处理方式**：向量按 row 的方式从上到下纵向进行。将整个向量按相同运算处理完之后，再进行别的运算。不产生数据相关，对向量长度 N 没有限制。
- **纵横处理方式**：把向量分成若干组，组内按纵向方式处理，依次处理各组。对向量长度 N 没有限制，但以每 n 个元素分一组处理，n 的值固定。

==存储器-存储器结构：适合纵向处理方式
寄存器-寄存器结构：适合纵横处理方式==

把能在同一个时钟周期内一起开始执行的几条向量称为一个**编队**。
同一个编队中的向量指令之间一定不存在流水功能部件的冲突或数据相关性。

在**链接**的时候，编队的含义就不是并行了，而是编队内的指令可以**连接**。
![](Attachments/Pasted%20image%2020250621204454.png)
![](Attachments/Pasted%20image%2020250621204501.png)
![](Attachments/Pasted%20image%2020250621204510.png)

![](Attachments/Pasted%20image%2020250621204906.png)
![](Attachments/Pasted%20image%2020250621205014.png)

---

# 第五章、指令级并行及其开发——硬件方法
## 指令集并行基础概念
**指令集并行**（ILP）是指令间存在的一种并行性，使计算机可以并行执行两条及以上的指令。

开发 ILP 的途径：
① 资源重复（重复设置多个部件同时执行多条指令）
② 采用流水线技术使指令重叠并行执行。

## 动态调度技术
- **记分牌算法**
 > 每条指令的执行过程分为 4 段——IS 流出、RO 读操作数、EX 执行、WB 写结果。
 > **指令状态表**：记录正在执行的各条指令已经进入哪一段
 > **功能部件状态表**：记录各个功能部件的状态。每个功能部件有 1 项，每项由 9 个字段组成。
 > > Busy：忙标志，功能部件是否正忙。
 > > Op：正在或将要执行的操作。
 > > $F_i$：目的寄存器编号，Fj,Fk：源寄存器编号。（按指令中的顺序排列）
 > > Qj,Qk：向源寄存器 Fj/Fk 写数据的功能部件
 > > Rj,Rk：源寄存器标志位，“yes”表示 Fj/Fk 的操作数**可用——就绪且未被取走（产生且未读）**。否则“no”。
 > **结果寄存器状态表**
 > 每个寄存器在该表中有一项，用于指出哪个功能部件（编号）将把结果**写入**该寄存器。![](Attachments/Pasted%20image%2020250622140720.png)

记分牌算法的冲突分析：
- WAW 冲突会导致记分牌在流出阶段停顿。
- WAR 冲突会导致记分牌在写结果阶段停顿。
- 真相关引起的 RAW 冲突会导致记分牌在读操作数阶段停顿。
- 资源冲突会导致记分牌在流出阶段停顿。

- **Tomasulo 算法**
 > 流出、执行、写结果
 > **指令状态表**
 > **保留站**
 > > Busy
 > > Op
 > > Vj,Vk：源操作数的值，如`Reg[F4]​`。对于每一个操作数来说，V 或 Q 字段只有一个有效。
 > > Qj,Qk：将产生源操作数的保留站号。0 表示操作数已就绪且在 Vj/Vk 中，或者不需要操作数。
 > > A：仅 load 和 store 缓冲器有该字段。开始先存放指令中的立即数字段，地址计算后存放有效地址。
 > **结果寄存器状态表**![](Attachments/Pasted%20image%2020250622141122.png)

==Tomasulo 算法的优点==：
- 冲突检测逻辑和指令执行控制是分布的（通过保留站和 CDB 实现）。
- 通过**寄存器换名和预约**，消除了 **WAW 冲突和 WAR 冲突导致的停顿**。
- 通过**延迟执行解决 RAW 冲突**。
- 保留站、寄存器组均有附加信息，用于检测和消除冲突。

- 基于硬件的前瞻执行
 > 在 tomasulo 算法后再加一步确认
 > 新加一个 ROB 表
 > ![](Attachments/Pasted%20image%2020250622140701.png)

## 动态分支预测技术

==**程序执行的CPI = 没有分支的基本CPI + 分支带来的额外开销**==

分支带来的额外开销是指在分支指令中，缓冲命中但预测错误带来的开销与缓冲没有命中带来的开销之和。

动态分支预测技术目的：① 预测分支是否成功。② 尽快找到分支目标地址或指令。
动态分支预测技术需要解决的问题：① 如何记录分支的历史信息。② 如何根据这些信息预测分支去向，甚至提前取出分支目标指令。

### 分支历史表 BHT
![](Attachments/Pasted%20image%2020250622135520.png)
BHT 两个步骤：
- 分支预测：当分支指令到达 ID 时，从 BHT 读出的信息进行分支预测。若正确就继续处理后续指令。若错误就作废预取指令，恢复现场，并从另一条分支路径重新取指。
- 状态修改：修改 BHT 状态。

### 分支目标缓冲器 BTB
分支目标缓冲器 Branch-Target Buffer 作用：
- 将分支成功的分支指令的地址，和它的分支目标地址都放到一个缓冲区中保存。
- 缓冲区以分支指令的地址作为标识，得到转移目标指令地址信息。
- 在 IF 段访问 BTB，将分支的开销降为 0。

![](Attachments/Pasted%20image%2020250622135726.png)

---

# 第九章、互联网络
## 互连函数
- **恒等函数**  $I(x_{n−1}x_{n−2}...x_1x_0)=(x_{n−1}x_{n−2}...x_1x_0)$
- **交换函数**：$Cube_k$ 实现二进制地址编号中**第 k 位**互反。用于构造立方体和超立方体互连网络
- **均匀洗牌函数**：
 > 均匀洗牌：$σ(x_{n−1}x_{n−2}...x_1x_0)=x_{n−2}x_{n−3}...x_1x_0x_{n−1}$，将入线二进制地址循环**左移一位**得到。
 > 逆均匀洗牌：循环右移
 > 第 k 个子函数：把互连函数作用于低 k 位。（下标）
 > 第 k 个超函数：把互连函数作用于高 k 位。（上标）
- **碟式函数**：$β(x_{n−1}x_{n−2}...x_1x_0)= x_0x_{n−2}...x_1x_{n−1}$。将输入端二进制最高位 $x_{n−1}$ 与最低位 $x_0$ 互换位置得到。
- **反位序函数**：$ρ(x_{n−1}x_{n−2}...x_1x_0)=x_0x_1...x_{n−2}x_{n−1}$，把输入二进制编号各位次序颠倒。
- **移数函数**：$α(x)=(x±k)mod\ N$ 把二进制编号模 N
- **PM2I函数**：加减 $2^i$。构成数据变换网络的基础。实质为 1、2、4 个环形网

## 结构参数与性能指标
6 个结构参数：
- 网络规模 N
- 结点度 d：结点所连接的边数。（入度、出度）
- 结点距离：从一个结点出发到另一个结点，经过边数的最小值。
- 网络直径 D：网络中结点距离的最大值。（越小越好）
- 等分宽度 b：把网络均分为结点数相同的两半，在各种切法中，沿切口边数的最小值。线等分宽度 B=b×w，w 为通道宽度（bit），等分宽度反映网络最大流量。
- 对称性：从任意结点看，网络的结构都是相同的。


![](Attachments/Pasted%20image%2020250622150200.png)

## 消息传递机制
两类四种寻径方式
线路交换：建立物理通路再传递信息。
包交换
- 存储转发
- 虚拟直通路
- 虫蚀

---

# 第十章、多处理机
- 什么是缓存一致性？

- 共享Cache的两种更新协议？

- Cache一致性协议的两大类：在多个处理器中用来维护一致性的协议。
关键：跟踪记录共享数据块的状态
两类协议（采用不同的共享数据状态跟踪技术）

• 目录法（directory）：物理存储器中共享数据块的状态及相关信息均被保存在一个称为目录的地方。
• 监听法（snooping）：每个Cache除了包含物理存储器中块的数据副本之外，也保存着各个块的共享状态信息。
Cache通常连在共享存储器的总线上，各个Cache控制器通过监听总线来判断它们是否有总线上请求的数据块。

# 第十三章、阵列处理机
- 什么是阵列处理机？

- 阵列处理机的主要特点

