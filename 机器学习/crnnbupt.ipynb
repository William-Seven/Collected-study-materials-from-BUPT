{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12136061,"sourceType":"datasetVersion","datasetId":7608757}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# from beam_search import ctc_beam_search\nimport torch\nimport numpy as np\n\n# 支持字符集：0~9\nCHARS = \"0123456789\"\nCHAR2IDX = {c: i for i, c in enumerate(CHARS)}\nIDX2CHAR = {i: c for i, c in enumerate(CHARS)}\nNUM_CLASSES = len(CHARS) + 1  # CTC中需要加一个 \"blank\"\n\n\ndef ctc_beam_search(log_probs, beam_width=10):\n    \"\"\"\n    Beam Search 解码 CTC 输出\n    log_probs: Tensor (T, C) - 每个时间步的 log softmax 概率\n    返回: 最可能的字符序列字符串\n    \"\"\"\n    T, C = log_probs.shape\n    beam = [(\"\", 0.0)]  # 每个元素: (当前序列, log概率)\n\n    for t in range(T):\n        new_beam = {}\n        for seq, score in beam:\n            for c in range(C):\n                char = IDX2CHAR.get(c, \"\") if c < NUM_CLASSES - \\\n                    1 else \"\"  # blank 不加字符\n                new_seq = seq + char if c != NUM_CLASSES - 1 else seq\n                new_score = score + log_probs[t, c].item()\n\n                if new_seq in new_beam:\n                    new_beam[new_seq] = np.logaddexp(\n                        new_beam[new_seq], new_score)\n                else:\n                    new_beam[new_seq] = new_score\n\n        # 选出前 beam_width 个最高概率路径\n        beam = sorted(new_beam.items(), key=lambda x: x[1], reverse=True)[\n            :beam_width]\n\n    return beam[0][0]  # 返回最高得分序列\n\n\ndef encode_label(label_str):\n    \"\"\"\n    将字符串标签（如 \"012345\"）转为数字索引列表 [0,1,2,3,4,5]\n    \"\"\"\n    return [CHAR2IDX[c] for c in label_str]\n\n\ndef decode_label(label_idx_list):\n    \"\"\"\n    将预测数字索引（去重CTC输出）转为字符串，如 [0,1,1,2,2,3] -> \"0123\"\n    \"\"\"\n    res = []\n    prev = -1\n    for idx in label_idx_list:\n        if idx != prev and idx != NUM_CLASSES - 1:  # 排除blank\n            res.append(IDX2CHAR[idx])\n        prev = idx\n    return ''.join(res)\n\n\ndef pad_label(label_list, max_len=6):\n    \"\"\"\n    将标签列表pad到固定长度，适用于DataLoader（虽然CTC本身不要求）\n    \"\"\"\n    return label_list + [NUM_CLASSES - 1] * (max_len - len(label_list))  # 用blank填充\n\n\ndef decode_output(log_probs, method='beam', beam_width=10):\n    \"\"\"\n    解码模型输出\n    - log_probs: Tensor(T, C)\n    - method: 'argmax' or 'beam'\n    \"\"\"\n    if method == 'argmax':\n        pred = torch.argmax(log_probs, dim=1).cpu().numpy().tolist()\n        return decode_label(pred)  # 原CTC贪婪解码\n    elif method == 'beam':\n        return ctc_beam_search(log_probs, beam_width=beam_width)\n    else:\n        raise ValueError(\"Unsupported decode method.\")\n\n\ndef decode_ctc_postprocess(log_probs, blank=10, max_repeat=2):\n    \"\"\"\n    改进版 CTC 解码器：保留重复，但限制重复次数（防止重复拖尾）\n    Args:\n        log_probs: (T, C)\n        blank: blank 标签索引\n        max_repeat: 每个数字最多重复次数（避免 111111 → 111）\n\n    Returns:\n        字符串预测结果\n    \"\"\"\n    preds = torch.argmax(log_probs, dim=1).detach().cpu().numpy().tolist()\n\n    result = []\n    last_char = None\n    repeat_count = 0\n\n    for p in preds:\n        if p == blank:\n            last_char = None\n            repeat_count = 0\n            continue\n\n        if p == last_char:\n            repeat_count += 1\n        else:\n            repeat_count = 1\n            last_char = p\n\n        if repeat_count <= max_repeat:\n            result.append(p)\n\n    return ''.join(str(c) for c in result)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:10:27.405633Z","iopub.execute_input":"2025-06-12T01:10:27.405871Z","iopub.status.idle":"2025-06-12T01:10:31.723049Z","shell.execute_reply.started":"2025-06-12T01:10:27.405849Z","shell.execute_reply":"2025-06-12T01:10:31.722207Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass CRNN(nn.Module):\n    def __init__(self, img_height=32, num_classes=11, rnn_hidden=128, rnn_layers=2):\n        super().__init__()\n\n        self.cnn = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, padding=1),    # Layer 1\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # H → H/2\n\n            nn.Conv2d(64, 128, kernel_size=3, padding=1),  # Layer 2\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # H → H/4\n\n            nn.Conv2d(128, 256, kernel_size=3, padding=1), # Layer 3\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # H → H/8\n\n            nn.Conv2d(256, 256, kernel_size=3, padding=1), # Layer 4\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),  # H → H/16\n        )\n\n        # feature_compression: (B, W, 256×H') → (B, W, 256)\n        self.feature_compression = nn.Linear(256 * (img_height // 16), 256)\n\n        self.rnn = nn.LSTM(\n            input_size=256,\n            hidden_size=rnn_hidden,\n            num_layers=rnn_layers,\n            bidirectional=True,\n            dropout=0.1,\n            batch_first=False\n        )\n\n        self.dropout = nn.Dropout(0.3)\n        self.fc = nn.Linear(rnn_hidden * 2, num_classes)\n\n    def forward(self, x):\n        conv = self.cnn(x)                  # (B, 256, H', W')\n        B, C, H, W = conv.size()\n        conv = conv.permute(0, 3, 1, 2)     # (B, W, C, H)\n        conv = conv.reshape(B, W, C * H)    # (B, T, 256×H')\n        conv = self.feature_compression(conv)  # (B, T, 256)\n        conv = conv.permute(1, 0, 2)        # (T, B, 256)\n\n        rnn_out, _ = self.rnn(conv)\n        rnn_out = self.dropout(rnn_out)\n        output = self.fc(rnn_out)           # (T, B, num_classes)\n        return output\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:10:37.264512Z","iopub.execute_input":"2025-06-12T01:10:37.264877Z","iopub.status.idle":"2025-06-12T01:10:37.273109Z","shell.execute_reply.started":"2025-06-12T01:10:37.264854Z","shell.execute_reply":"2025-06-12T01:10:37.272397Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nimport torch\nfrom torch.utils.data import Dataset\nfrom PIL import Image\nimport pandas as pd\nfrom torchvision import transforms\n# from utils import encode_label\nimport random\n\n\nfrom torchvision import transforms\nfrom torchvision.transforms import InterpolationMode\nimport torch\nimport random\n\n\ndef get_train_transform(img_height, img_width):\n    return transforms.Compose([\n        transforms.Resize((img_height, img_width)),\n        transforms.RandomRotation(degrees=2),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,)*3, (0.5,)*3)\n    ])\n\n\ndef get_test_transform(img_height, img_width):\n    return transforms.Compose([\n        transforms.Resize((img_height, img_width), interpolation=InterpolationMode.BICUBIC),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,)*3, (0.5,)*3)\n    ])\n\n\nclass MeterDigitDataset(Dataset):\n    def __init__(self, csv_file, image_dir, img_height=32, img_width=128, is_train=True):\n        self.data = pd.read_csv(csv_file)\n        self.image_dir = image_dir\n        self.img_height = img_height\n        self.img_width = img_width\n        self.is_train = is_train\n\n        # self.transform = transforms(img_height, img_width)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        filename = row['filename']\n        label_str = str(row['label']).zfill(6)\n\n        # 加载图像\n        img_path = os.path.join(self.image_dir, filename)\n        image = Image.open(img_path).convert('RGB')\n        image = self.transform(image)\n\n        # 编码标签\n        label_encoded = encode_label(label_str)\n\n        label_length = len(label_encoded)\n        input_length = self.img_width // 16\n\n        return {\n            'image': image,\n            'label': torch.tensor(label_encoded),\n            'label_length': torch.tensor(label_length),\n            'input_length': torch.tensor(input_length),\n            'filename': filename\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T14:03:52.846351Z","iopub.execute_input":"2025-06-11T14:03:52.847001Z","iopub.status.idle":"2025-06-11T14:03:56.503473Z","shell.execute_reply.started":"2025-06-11T14:03:52.846978Z","shell.execute_reply":"2025-06-11T14:03:56.502734Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\n# from crnn_model import CRNN\n# from crnn_model import CRNNTransformer\n# from dataset import MeterDigitDataset\n# from utils import NUM_CLASSES\nfrom torch.utils.data import Subset, random_split\n# from utils import decode_label\n# from dataset import MeterDigitDataset, get_train_transform, get_test_transform\n# from utils import decode_output\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\n\ndef train_model(\n    image_dir,\n    label_csv,\n    epochs=40,\n    batch_size=32,\n    lr=1e-4,\n    img_height=32,\n    img_width=128,\n    checkpoint_dir='/kaggle/working/'\n):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    full_dataset = MeterDigitDataset(\n        csv_file=label_csv,\n        image_dir=image_dir,\n        img_height=img_height,\n        img_width=img_width\n    )\n\n    total_len = len(full_dataset)\n    train_len = int(total_len * 0.9)\n    val_len = total_len - train_len\n\n    train_indices, val_indices = torch.utils.data.random_split(\n        range(total_len), [train_len, val_len], generator=torch.Generator().manual_seed(42)\n    )\n\n    train_dataset = Subset(full_dataset, train_indices)\n    train_dataset.dataset.transform = get_train_transform(img_height, img_width)\n\n    val_dataset = Subset(full_dataset, val_indices)\n    val_dataset.dataset.transform = get_test_transform(img_height, img_width)\n\n    train_loader = DataLoader(\n        train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n\n    model = CRNN(img_height=img_height, num_classes=NUM_CLASSES).to(device)\n    criterion = nn.CTCLoss(blank=NUM_CLASSES - 1, zero_infinity=True)\n    optimizer = Adam(model.parameters(), lr=lr)\n    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n\n    best_loss = float('inf')\n    best_acc = 0.0\n    os.makedirs(checkpoint_dir, exist_ok=True)\n\n    for epoch in range(1, epochs + 1):\n        model.train()\n        total_loss = 0\n\n        for batch in train_loader:\n            images = batch['image'].to(device)\n            labels = batch['label'].to(device)\n            label_lengths = batch['label_length'].to(device)\n            outputs = model(images)\n            input_lengths = torch.full(size=(images.size(0),), fill_value=outputs.size(0), dtype=torch.long).to(device)\n\n            optimizer.zero_grad()\n            log_probs = nn.functional.log_softmax(outputs, dim=2)\n            loss = criterion(log_probs, labels, input_lengths, label_lengths)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n        avg_loss = total_loss / len(train_loader)\n\n        # === 验证 ===\n        model.eval()\n        val_loss = 0\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for batch in val_loader:\n                images = batch['image'].to(device)\n                labels = batch['label'].to(device)\n                label_lengths = batch['label_length'].to(device)\n\n                outputs = model(images)\n                input_lengths = torch.full(size=(images.size(0),), fill_value=outputs.size(0), dtype=torch.long).to(device)\n                log_probs = nn.functional.log_softmax(outputs, dim=2)\n                loss = criterion(log_probs, labels, input_lengths, label_lengths)\n                val_loss += loss.item()\n\n                preds = torch.argmax(log_probs, dim=2).permute(1, 0)\n\n                for i in range(images.size(0)):\n                    log_prob = log_probs[:, i, :]\n                    pred_str = decode_output(log_prob, method='argmax')[:6].ljust(6, '0')\n                    start = int(sum(label_lengths[:i]))\n                    end = start + int(label_lengths[i])\n                    true_seq = labels[start:end].detach().cpu().numpy().tolist()\n                    true_str = decode_label(true_seq)[:6].ljust(6, '0')\n\n                    if pred_str[:5] == true_str[:5]:\n                        correct += 1\n                    total += 1\n\n        acc = correct / total\n        avg_val_loss = val_loss / len(val_loader)\n        print(f\"Epoch {epoch}: train_loss = {avg_loss:.4f} | val_loss = {avg_val_loss:.4f} | val_acc = {acc:.2%}\")\n\n        scheduler.step(avg_val_loss)\n\n        # === 保存 val_loss 最低的模型 ===\n        if avg_val_loss < best_loss:\n            best_loss = avg_val_loss\n            torch.save(model.state_dict(), os.path.join(checkpoint_dir, 'new_best_model.pth'))\n            print(\"Best model (val_loss) updated.\")\n\n        # === 保存 val_acc 最高的模型 ===\n        if acc > best_acc:\n            best_acc = acc\n            torch.save(model.state_dict(), os.path.join(checkpoint_dir, 'best_acc_model.pth'))\n            print(\"Best model (val_acc) updated.\")\n\n\n# === 用于CTC的collate函数：拼接label序列 ===\n\n\ndef collate_fn(batch):\n    # 自动拼接 label、image 等变量，处理不等长序列\n    images = torch.stack([b['image'] for b in batch])\n    labels = torch.cat([b['label'] for b in batch])\n    label_lengths = torch.stack([b['label_length'] for b in batch])\n    input_lengths = torch.stack([b['input_length'] for b in batch])\n    filenames = [b['filename'] for b in batch]\n    return {\n        'image': images,\n        'label': labels,\n        'label_length': label_lengths,\n        'input_length': input_lengths,\n        'filename': filenames\n    }\n\n\n# === 主函数入口 ===\nif __name__ == '__main__':\n    image_dir = '/kaggle/input/numdigit/cropped_digits'\n    label_csv = '/kaggle/input/numdigit/labels.csv'\n\n    train_model(\n        image_dir=image_dir,\n        label_csv=label_csv,\n        epochs=45,\n        batch_size=16,\n        lr=1e-4\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T14:04:00.449092Z","iopub.execute_input":"2025-06-11T14:04:00.449737Z","execution_failed":"2025-06-11T14:05:25.807Z"}},"outputs":[{"name":"stdout","text":"Epoch 1: train_loss = 2.3936 | val_loss = 2.3417 | val_acc = 0.00%\nBest model (val_loss) updated.\nEpoch 2: train_loss = 2.1705 | val_loss = 2.0887 | val_acc = 0.00%\nBest model (val_loss) updated.\nEpoch 3: train_loss = 1.8503 | val_loss = 1.8188 | val_acc = 0.00%\nBest model (val_loss) updated.\nEpoch 4: train_loss = 1.4580 | val_loss = 1.5807 | val_acc = 1.19%\nBest model (val_loss) updated.\nBest model (val_acc) updated.\nEpoch 5: train_loss = 1.0927 | val_loss = 1.0921 | val_acc = 25.00%\nBest model (val_loss) updated.\nBest model (val_acc) updated.\nEpoch 6: train_loss = 0.8223 | val_loss = 0.7650 | val_acc = 70.24%\nBest model (val_loss) updated.\nBest model (val_acc) updated.\nEpoch 7: train_loss = 0.6109 | val_loss = 0.6448 | val_acc = 71.43%\nBest model (val_loss) updated.\nBest model (val_acc) updated.\nEpoch 8: train_loss = 0.4716 | val_loss = 0.6258 | val_acc = 78.57%\nBest model (val_loss) updated.\nBest model (val_acc) updated.\nEpoch 9: train_loss = 0.3781 | val_loss = 0.6108 | val_acc = 72.62%\nBest model (val_loss) updated.\nEpoch 10: train_loss = 0.3241 | val_loss = 0.5572 | val_acc = 66.67%\nBest model (val_loss) updated.\nEpoch 11: train_loss = 0.2667 | val_loss = 0.4862 | val_acc = 75.00%\nBest model (val_loss) updated.\nEpoch 12: train_loss = 0.1915 | val_loss = 0.4080 | val_acc = 73.81%\nBest model (val_loss) updated.\nEpoch 13: train_loss = 0.1425 | val_loss = 0.4474 | val_acc = 76.19%\nEpoch 14: train_loss = 0.1066 | val_loss = 0.4603 | val_acc = 63.10%\nEpoch 15: train_loss = 0.0786 | val_loss = 0.4879 | val_acc = 72.62%\nEpoch 16: train_loss = 0.0609 | val_loss = 0.3814 | val_acc = 76.19%\nBest model (val_loss) updated.\nEpoch 17: train_loss = 0.0457 | val_loss = 0.3944 | val_acc = 82.14%\nBest model (val_acc) updated.\nEpoch 18: train_loss = 0.0356 | val_loss = 0.4023 | val_acc = 79.76%\nEpoch 19: train_loss = 0.0286 | val_loss = 0.4117 | val_acc = 78.57%\nEpoch 20: train_loss = 0.0233 | val_loss = 0.4278 | val_acc = 78.57%\nEpoch 21: train_loss = 0.0195 | val_loss = 0.4082 | val_acc = 82.14%\nEpoch 22: train_loss = 0.0184 | val_loss = 0.4207 | val_acc = 80.95%\nEpoch 23: train_loss = 0.0171 | val_loss = 0.4241 | val_acc = 79.76%\nEpoch 24: train_loss = 0.0158 | val_loss = 0.4297 | val_acc = 79.76%\nEpoch 25: train_loss = 0.0150 | val_loss = 0.4277 | val_acc = 79.76%\nEpoch 26: train_loss = 0.0149 | val_loss = 0.4397 | val_acc = 79.76%\nEpoch 27: train_loss = 0.0142 | val_loss = 0.4235 | val_acc = 79.76%\nEpoch 28: train_loss = 0.0134 | val_loss = 0.4383 | val_acc = 79.76%\nEpoch 29: train_loss = 0.0132 | val_loss = 0.4371 | val_acc = 79.76%\nEpoch 30: train_loss = 0.0128 | val_loss = 0.4457 | val_acc = 79.76%\nEpoch 31: train_loss = 0.0126 | val_loss = 0.4399 | val_acc = 79.76%\nEpoch 32: train_loss = 0.0123 | val_loss = 0.4398 | val_acc = 79.76%\nEpoch 33: train_loss = 0.0121 | val_loss = 0.4315 | val_acc = 79.76%\nEpoch 34: train_loss = 0.0121 | val_loss = 0.4375 | val_acc = 79.76%\nEpoch 35: train_loss = 0.0119 | val_loss = 0.4360 | val_acc = 80.95%\nEpoch 36: train_loss = 0.0121 | val_loss = 0.4418 | val_acc = 79.76%\nEpoch 37: train_loss = 0.0118 | val_loss = 0.4366 | val_acc = 79.76%\nEpoch 38: train_loss = 0.0116 | val_loss = 0.4364 | val_acc = 79.76%\nEpoch 39: train_loss = 0.0117 | val_loss = 0.4376 | val_acc = 79.76%\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport pandas as pd\nfrom PIL import Image\nfrom torchvision import transforms\n# from model import CRNN        \n# from utils import decode_output \n\ndef load_model(model_path, device, img_height=32, num_classes=11):\n    model = CRNN(img_height=img_height, num_classes=num_classes)\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    model.to(device)\n    model.eval()\n    return model\n\ndef get_transform(img_height=32, img_width=128):\n    return transforms.Compose([\n        transforms.Resize((img_height, img_width)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.5,)*3, (0.5,)*3)\n    ])\n\ndef predict_folder(image_folder, model_path, output_csv, img_height=32, img_width=128):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = load_model(model_path, device, img_height)\n\n    transform = get_transform(img_height, img_width)\n    results = []\n\n    image_files = sorted([f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n\n    for filename in image_files:\n        image_path = os.path.join(image_folder, filename)\n        image = Image.open(image_path).convert('RGB')\n        image = transform(image).unsqueeze(0).to(device)  # (1, 3, H, W)\n\n        with torch.no_grad():\n            output = model(image)        # (T, B, C)\n            log_probs = torch.nn.functional.log_softmax(output, dim=2)\n            pred = decode_output(log_probs[:, 0, :], method='argmax')[:6].ljust(6, '0')\n            # pred = decode_output(log_probs[:, 0, :], method='argmax')[:6].zfill(6)\n            # pred = decode_output_no_merge(log_probs[:, 0, :], blank=NUM_CLASSES - 1)[:6].ljust(6, '0')\n            # pred = decode_ctc_postprocess(log_probs, blank=10, max_repeat=3)[:6].ljust(6, '0')\n            # pred = decode_output(log_probs[:, 0, :])  # 解码第一个 batch 的预测\n            # ✅ 在最后一位前插入小数点，如 '09575.9'\n            pred = pred[:5] + '.' + pred[5]\n\n        results.append({'id': filename, 'number': pred})\n\n    df = pd.DataFrame(results)\n    df.to_csv(output_csv, index=False)\n    print(f\"预测结果已保存至：{output_csv}\")\n\nif __name__ == '__main__':\n    image_folder = '/kaggle/input/numdigit/cropped_digits_test'              \n    model_path = '/kaggle/input/numdigit/best_acc_model.pth'     \n    output_csv = 'prediction_results.csv'\n\n    predict_folder(image_folder, model_path, output_csv)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T01:10:57.441004Z","iopub.execute_input":"2025-06-12T01:10:57.441686Z","iopub.status.idle":"2025-06-12T01:11:02.719938Z","shell.execute_reply.started":"2025-06-12T01:10:57.441660Z","shell.execute_reply":"2025-06-12T01:11:02.719134Z"}},"outputs":[{"name":"stdout","text":"预测结果已保存至：prediction_results.csv\n","output_type":"stream"}],"execution_count":3}]}